what is going on guys my name is Rob win from volt.com and today I going to be showing you how you can use voice flow to create an automated customer service agent for your business whether you're a business owner whether you're an agency owner like me and you're creating this for someone else or if you just want to get the lay of the land with voice flow and figure out what's going on this video is going to be for you let's get right into it all right so here we are on the voiceflow dashboard now before we get fully into creating the chatbot I quickly wanted to go over the difference between using voice flow to create your agents and using something like chatbase because I know when I first got into it I was a little confused on what the difference was between those two basically with chat base it has the ability where you can upload a knowledge Source or a knowledge base and you can create very easily a question and answer chatbot just strictly simple question and answering it's great for that and it's very simple and easy to use but it can't do much more than that it can't really perform actions it can't integrate with outside sources update databases retrieve order information make API calls all that more complicated stuff that's what you'll want to use a service like voice flow for and there are others like bot press this tutorial is going to be focused on Voice Low it's the one I've used and I found it very easy to use intuitive and beginner friendly so with that quick note out of the way we will proceed with the creation of the agent here this is the dashboard like I said in order to get to this screen you'll obviously want to sign up create an account do all that there is no charge for using voice flow they do have a free plan you don't even need to put in a credit card you get two agents with that plan for free and up to 100,000 tokens per month so uh highly recommend it if you just want to try it out there is an affiliate Link in the description if you feel like doing that if not no worries at all but I'll wait for you to get it set up and get to the screen and then we will proceed by clicking the new agent button in the top right to start our our agent we'll go ahead and click that there go ahead and fill out these fields here with the appropriate things we'll just do a chat bot although there is the option for voice chat we'll hit continue it's going to ask for what authorize users we want we'll just leave that the way it's set right now then we'll hit create agent to bring us to the canvas for our new agent so here we are on the default canvas it sort of gives you a basic template for uh an agent I do actually encourage you to play around with this for a little bit just to see how it works like I said voice flow is pretty intuitive and beginner friendly so you can learn a lot just by playing around with the stuff seeing how the flows work seeing how the different boxes and actions work and maybe experimenting and try adding a few things yourself so I do encourage you to pause the video and just play around with this for now we will proceed you can select all items by clicking shift and then dragging your cursor it'll select everything and then we'll just go ahead and hit delete to delete everything to start with a fresh canvas so as you can see now we have the Simple Start trigger this is going to be the start of our flow anytime an interaction or a chat starts with our agent this is where it's going to start from and in order CH add things to this flow you can click this little button here and drag like this or you can go over here and you can come to this menu and you can click and drag the appropriate things as well we're going to start with the basic um message block this is the default me this is the default block if you just want to have your agent say something to the user you can click within it and then enter your agent message here so we're just going to have something really basic a greeting welcoming the user to our site something like that we'll do hello welcome to our website that sounds solid and then you can actually stack multiple things within a block you can see you can put it above below like that we'll put this one below and it'll just be a what can I help you with message to get the conversation going we'll want to link up our start trigger with this block so when we click Start it goes to this and now now we're actually going to run it and see what happens and you can see we've got our two separate messages there if I had just put all the text into one block it would have just been one line of code but you can break it up into multiple messages if you think that looks better for your use case and then it just ends you can see sess session ended because there's nothing else going on here we haven't prompted the user to input anything or anything like that now a quick note on testing I just want to say you should be testing your agents early and often test them as much as possible to make sure that they are doing exactly what you want them to that's very important so that you don't go through a whole bunch of steps only to find out when you test it at the end that it's not working the way you want to so be sure to test often you do have to keep an eye on your token you should sometimes because testing does use tokens but there's ways you can manage that so it doesn't use as many tokens when you're testing uh and you can still make make sure that it's doing exactly what you want so just a quick note on that so now in order to actually listen for a response from the user that's where this listen step comes in over here it means just listen wait and listen for the user to say something basically and you got three options you got buttons choice and capture buttons and choice are basically basically the same thing they both allow the user to free flow type things in just in plain English how they want it's just with buttons you also give some visual literal visual buttons that the user can click on in addition to them having the ability to type something out so those two are very similar and then capture just means whatever the user replies we're going to capture that and save it to a variable that's what that means so in this case we're going to Simply choose choice and just let the user say whatever ever they want we're going to click and drag it here and by the way just so you're aware voice flow is frequently doing updates so if you're watching this video in the future and things aren't named exactly the way that they are here or the layout's a little different don't freak out it was the same way for me when I was watching the tutorials for me to learn uh just it might take a minute to figure out the new thing but it's usually very similar and like I said pretty easy to understand so now we've got our capture block here and you can see it says listening for an intent so what does an intent mean it means basically what it says it's it's what is the user intending to do or what are they what are they trying to do now you actually as the voice flow Creator have to set this up and tell voice flow what the possible intents are there's not just an INF infinite number of them you have to specify exactly which intents you want it to listen for so if we run this test again we've got the two messages and then it does it doesn't end it does wait for us to type something but if we say something like I need text support and send that message in we get this sorry I didn't get that message and that's because we haven't configured any intents yet for it to actually listen to so there it can't really Define what the user says and fit it into a specific category it can only respond with this message no matter what we said so if we said in even we get the exact same response so to solve that what we want to do is start creating some intents and to do that you go ahead and click on this you'll go over here to select an intent for One path there's some default intents here just yes and no we'll create a new intent we'll call it Tex support like I just typed in you can type a description as well if you want and then these utterances These are what where you specify things that the user might say that are you want to direct to this intent so obviously what I just said I need text support that would be one you can hit enter I need help with my software would be another and then what you can do is use this AI generation tool by clicking here you can generate some sample phrases and it'll come up with a bunch for you that are similar IL to the first one that you put in here it's always going to go by the very first one now you do want to double check these because sometimes they're not exactly what you want so don't just click that and call it a day because the green confidence bar is full you do want to quickly go over that to make sure your agent is routing them appropriately so if you don't want any you can just click this negative sign and it'll take them away also what I recommend doing here is if you have like a user might say multiple different things and you all wanted to Route it to the same intent because the AI here can only generate based on that first one that you says or said you can just use chat gbt or another large language model for help generating a bunch of utterances that the user might say can also do it where you know yall know people don't always type say things exactly the way you would say them people uh misspell words there's people who your native language isn't there native language so they they type things with incorrect grammar stuff like that you can also instruct chat gbt to give you some of those utterances uh you want to have a good variety uh a good coverage of the different things people could say to make sure you're getting it everything to the right intent and this is a thing another thing that takes a lot of testing to make sure you're getting it right so again with these do you want to make sure through tests that you want to try a variety of different ways of saying the same thing to make sure it is correctly routing to the intent but for now we're just going to go with these we'll assume all these look good for our purposes in this tutorial they do we'll click create intent and now we can see our tech support intent filled or populates that path over there and now when we run our test let's take a look oh actually first we need to go ahead and train our model that's what when you see this little red dot it means the agent needs training this usually happens when you you modify your intents or potentially the knowledge base it says it may take a few minutes but I've never seen it take more than like 20 seconds so it's really not too bad see it's already trained now we can proceed we'll say I need text support I need text support just like before now this time the session does end and it says no intent matched but actually you can see here now we do have text support at 100% And that tech support is an indicator of the intent that we set up it is matching to the TCH support intent with 100% confidence and a way to get this figure up if you don't see it on your screen is to click this little settings button for the test and go into debug mode and then show the intent confidence score as well I think this is clicked off by default yeah you can see It'll show show up when we when we click it there so I highly recommend both of those just for troubleshooting purposes and also I want to show you this tab real quick over on the left if you click this little bar it'll pop out with all the variables and their current values as you go through the test that can be very helpful as well for debugging so now that our agent in this step is listening for intense and we have the text support setup or in tech support intent setup what do we want to have happen when someone we detect that intent that's where we can click the little circle and drag and then create a path from here now for this tutorial we're just going to create make it real simple and just create a message that says it's going to trigger the text support process but obviously for when you're creating your own bonds you can build this out however you want uh you can if you get into the more complicated stuff which we will a little bit later I'll show you how to use make.com Integrations to integrate with the agent here you can create tickets use zenes that sort of thing but for now we'll just leave it at this so we can move on with the tutorial now in order to create additional intents cuz obviously there's other things besides tech support that a user might want to do you can go ahead and click add Choice here by going back to the listen button click add choice and you'll have the option to add another intent and you can do this pretty much as many times as you want we'll go ahead and create a new intent here we'll do billing do the same thing where we create some sample UT utterances and use the generate function to populate a bunch and we'll go ahead and create that intent as well so we have two intents up and running I'll create a simple path for this one just for completeness and a quick note on intent confidence score we saw before when we did the test run it was 100% confident that what we said would go to the tech support intent but often it's not that it might only be 60% sure 80% sure you can adjust that setting so that the I think the the confidence threshold by default is 60% if it's 60% for sure 60% sure you want to go to a particular intent it will route it that way but you can adjust that 50 you want it to be more confident 80 90 something like that just a quick note on the confidence threshold so one other quick thing with intents I wanted to show you is the trigger function and if you right click on the canvas and you click this button called add trigger you'll get a button like this similar to the start button but for this one it's going to connect to an intent so if you click on it and then you click the little plus sign by triggers you'll see a list of intents here and you can click one and what this means is if it detects an intent it will route to this so this can be an alternative to adding the path directly from here like we could say instead of that we could have have it go to this action and go to intent and then we can select this intent under home and then text support and it'll route here now one thing about these triggers you have to keep in mind is that they will listen globally in the conversation so in another part of the conversation like way down in your workflow if it detects that the user wants text support this will listen for it and it will pick it up and it'll route and it'll start over here so that's something to keep in mind when using these triggers but I'll go ahead and delete this I just wanted to point it out because that is another option you can use in your workflows all right now what if the user inputs something that is not tech support or billing what if they have a question about our services or what our prices are or anything about our business that's where the knowledge base and the actual AI portion of the flow can come in so we'll go ahead and click on this Choice box and then for no match basically saying it doesn't match any of the intents what do we want to have happen we'll click on that and then we'll click path here to allow us the option to create a different path for when there is no match and then we can click the little circle drag it and now we have what's going to happen when they ask let's just say what happens when they ask what services we offer that's where we'll click and drag and we want the AI to answer that question so we click this there's two options under AI there's set Ai and response AI response AI is where you are responding to the user's question which we'll use here set AI is where you're going to use AI to set variables similar to the listen step where we captured the user response and set it to a variable set AI we're going to be taking the AI response and setting saving that to variables but for now we actually just want to directly respond to the user's question so we'll click response AI and then we have two options for our data source when we do that we have just the basic AI model and everything it was trained on all the information on the web that sort of thing and then we have knowledge base which is the custom information specific to your business it's basically what it sounds like it's a base of knowledge maybe some frequently asked questions some information about your business anything you would want to possibly convey to a user using this agent here you could put into your knowledge base and the way that it works is if you're if you're familiar with the concept of a vector database that's essentially what it is it'll break down all the knowledge into vectors and score it and then based on the user's query the model will retrieve the relevant parts of the knowledge base to answer the user's question so it's not like it's sending the entire knowledge Place base plus the user's question to the large language model and getting the response in order to be practical and save tokens it can figure out what are the most relevant sections or chunks as they're called of the knowledge base extract those then send those chunks plus the user's question as the prompt to the large language Model results in a much smaller prompt uh much more token save but also uh very ACC accurate answers because it has the chunks it has the information that it needs to answer the user's question so if we go ahead and select the knowledgebase option we'll see there's two fields that we can potentially enter first one is question that's the query that we're going to send to the knowledge base so that it retrieves the appropriate information from the knowledge base now for our uses here in this one what we want to send is a variable not just we don't just want to free type a question we actually want to say what the user asked so that variable is kept in voice F by default under the variable last utterance you can access the list of variables by doing the curly brackets opening and then it will give you all the list of the the variables that are available last utterance is going to be the one that the users query their most recent input into the chat system that's what it's saved under and since this one there's only one message that could have possibly sent to trigger this it's going to be the last one so that's why we choose last utterance for the question there instructions for the response we're just going to leave blank we don't need any special formatting right now for our knowledge based retrieval we just need it we just need the information basically so we can leave that one blank you'll also see the option here to override prompt settings which you can click on if you toggle that on it'll give you various options you can change the model if you'd like to chat GPT you can adjust the temperature up or down we'll keep that low the tokens that it retrieves from the model depending on your use case usually around 200 is probably good you don't want to be it to be too wild on the temperature if you're unsure of what all that means go ahead and watch my previous video on the large language model uh prompting fundamentals so you can learn about that the system message you can or we will leave blank at the moment but you can enter a system message if You' like and then you can also preview something by entering a value for like a sample user question we can't do anything because we haven't input a knowledge base yet we can't preview that but that's how you would do that if you wanted to so the next thing we'll go over is how to actually construct this knowledge base for your business you probably have things available depending on your situation already some information about the business you can also link specific URLs or web pages or even a s map and it will just read the information directly from the site in this case I created a specific document for the knowledge based had basically like a list of FAQs and for to to build it out I used chat GPT here's the prompt I gave it and it gave me its sample response and then I just slowly built out using a similar prompt as this the different sections of the knowledge base and you can use this not only to build out your knowledge base but also for constructing uh your intents you constructing questions that users might ask you know just say hey chap GPT can you give me a list of sample questions that visitors might ask this agent that I'm building uh my business is this and it'll give you a big long list of potential questions you can modify those you can tell it to be more creative you can use it for all sorts of gener generation like this obviously you'll want to go through its result and modify it but this is how you get the base this is how you get the format the base information and then you can go in and adjust it based on your particular business now once you actually have the knowledge base built out and that can take some time obviously but once you have it built out and it's it's pretty accurate in order to load it into your model so that it can actually be used by the agent you'll want to go back to the dashboard for your agent this screen right here you have a subl list of different options over here uh the one we'll want to go to is knowledge right now there's no data sources so we'll go ahead and click add a data source I'm going to upload a file you can do various things and we're going to upload our V volti knowledge base import it and it's loaded pretty easy now to get back to our workflow we'll go ahead and click workflows then you double click this line that's the easiest way it'll take you right back in there and now we have our knowledge base all loaded in and now when we start the chat we'll get this message we'll say what types of services do you offer it's not text support or billing so it should route to the knowledge base and you get the answer because it knows it's not Tex support it's not building so it sends that query to the knowledge base instead the knowledge base is able to find that information or excuse me the model is able to find that information in the knowledge base and so we get an answer here now just to show you what happens if you type something completely random nothing happens here because that question is not found in the knowledge base and also Al we haven't established a path for not found when it's not found in the knowledge place there's nothing there so it just ends the chat doesn't answer the user's question because it can't and there's no additional path for what to do when that happens so it just ends and by the way since we have them up here this information over here is your token usage it shows you how many tokens were sent to the model and then the adjusted amount of tokens that were used against your voice flow account quota based on the model that you're using because chat chat gbt 3.5 is a cheaper model it's only 6 of the amount of the standard amount of tokens that it used one thing I wanted to mention real quick I'm back in the knowledge based screen you might have seen it on your own but I wanted to go over it real quick if you click the settings button here this is going to open up the settings for the knowledge base specifically you can change the model you can change the temperature of the max tokens you can change the chunk limit usually like two to three three is going to be best for simple uh FAQ type type situations where your knowledge base should be able to retrieve most of the information I like to change this system message here because frankly it doesn't make sense to me says your responses should be fewer than a couple of sentences which is sort of uh paradoxical I like to change it to just your responses should be a couple of sentences something like that you can adjust it for your use case obviously but but I like to modify that so what if our model can't answer our question from the knowledge base like when we ask it a completely random question or if a user just ask it a question that's relevant but just for whatever reason not included in our knowledge base that's where this not found path comes in you can just create this you can do whatever you want we're just going to create a simple message saying hey sorry we couldn't find the message but go ahead and email me directly for an answer to the question I'd be happy to help you out so I'm going to put that in real quick you can do whatever you want obviously in your chat Bots but that's how you would handle something like that so now no matter what whether we were able to answer the user's question or not we're going to create a new message here and just say ask if there's anything else we can help the user with today and you can see underneath there's this variance line this gives you the option to add variance manually so it's not saying the same thing every time or you can do it again with AI similar to before when we created utterances with generative AI this is a similar thing and then you can choose which things you want to accept we'll just do these three so now it'll randomly pick one when we get to this step we're going to go ahead and connect both when we're able to answer the user's question with the knowledge base and also when we are not we're going to want to go up to this block as well so both want are going to ask is there anything else we can help with today and then the user's going to say something so we need to listen for that answer this time we'll go ahead and put some buttons in there again with buttons the user can still just type free flow this just gives them some additional options we'll put a button in there for yes we'll put add a button and we'll put a button in there for no you can also attach a tense to intense to the button so instead of clicking yes they actually say yes that's where you can attach the yes intent you can do that for no as well or any other intent or button combination you want to have now let's say we test this and we get the message here and it gives us the buttons that we just put in but let's see now user puts in one of the intents from this previous step like text support or billing you can see even though that it recognized tech support was the intent of the user there was no path there was no intent listed here for Tex support to maybe go down this and Trigger this tech support process so that's where before when I talked about these triggers these intent triggers if we get out of this test and we go to add trigger uh this if you set up a trigger like this it will look listen I should say for Tex support intent throughout the entire chat and if it had been up when we went through this test it would have detected that the user wanted text support and it would have routed it here so that's a a situation where you might want to use those triggers if you have multiple places where the user can input information and you want to listen for intense in all of those places just something to keep in mind so going back to these buttons what do we do if a user says or clicks on yes we can route that to wherever we want we're going to Route it back to just right back to what can I help you with today we'll start that process again and what about no if they say no they don't need anything else well in that case we will want to Simply end the chat you can do that under the action section here and just click and that will just end the chat but what if somebody just ask another question like what is your pricing or do you have any deals going on well in that case we would want to Route it back to the knowledge base and so to do that we'll go ahead under this button section what if there's no match that's where we click this little path here and then we click this little plus button next to path and now we'll get this pop out for when there's no match to either of these intents so what do we want to do we want to send it back to this new block 4 and here real quick I'll show you you can actually title these blocks and then for the path you can simply go to that particular block you draw the arrow you'll go under actions there's going to be an option to go to block you might have seen that and then you simply select the block users's question now when they ask another question it will simply route to this block we'll send it back to the knowledge base it'll either answer it if it can or it'll say not found sorry I couldn't find the answer so let's say we wanted to add some functionality where if a user ask three questions in a row and they get their answers we want to do a sort of lead capture step where we ask them if they're interested in scheduling a consultation how would we do that well first we would go in and we would delete this direct connection from the answer of the user's last utterance to the is there anything else I can help with question we'll delete that connection just by clicking on it and click delete and we'll want to utilize some of these logic steps over here to set up some variables and also trigger a certain condition if a variable is set so let's say we wanted to do it where if they ask three questions in a row we want to trigger the lead capture step we'll go ahead and use this set variable block under logic and then we'll go to variables to set we'll want to select the variable from this list now we actually don't have the variable that we want yet we'll want to create a variable which you can do by clicking here variable name here we'll just do number of questions you can enter a description if you like and a default value the default value is zero so we'll just keep it at that and click create variable and then we'll click this to actually set it to something so every time this block is triggered what we wanted to set it to is the number of questions plus one so it'll basically keep a counter are going and we can keep track of the number of questions that way so each time this block is triggered it's going to go from 0 to 1 1 to two 2 to three and you'll be able to see that when you test which we'll do in a minute that the variable is actually changing as we go through the flow so we'll connect it up here and now what happens when it actually hits the criteria that we set what happens when we get to number of questions equals three we'll go back to logic we'll use this if condition you click that with we can drag it right under there and then we'll put in we can enter a label if we want check number of cues and then we can actually add the condition now obviously if you're familiar with programming this will be pretty straightforward if not I think you can figure it out we are checking if a particular variable number of questions is in our case we're doing three that's the criteria if number of questions is three you can add additional conditions if you want to do Andor statements but that's the basic one that we're doing now what do we want to have happen after that we're going to send it to the lead capture step which we'll put up here we'll ask them if they're interested in scheduling a free consultation with one of our Representatives then we can add some buttons for yes for no you get the idea you can initiate your lead capture here uh you can definitely do it where you ask use the agent to get the information you know their name their email their phone number whatever it is uh and then populate that in a database on the back end or send an email with that information uh I've done a where it just links to the form on my website whatever you want to do but we won't get all the way into that we'll just leave it at this but that's how you would do that part of the step and after you set up the if condition to check if the number of questions is three if it's not that's where you'll use this no math or no match again it's basically the else statement in that case we will want to just route straight to is there anything else I can help you with today so now we've got that set up we direct them to the form on our website if not we just route them back to the beginning of the conversation here and keep in mind you can use something like this for really anything it could be you know signing up for your newsletter joining the email list get a free guide lead magnets that sort of thing anything you want to do you can pretty much configure it in voice flow using something similar to this so let's test our agent from the beginning we'll click Start here we'll ask first what service we have and you can see here the number of questions variable was updated from 0 to one that's how it shows that in the debug mode when you're doing your test we'll click yes for can I assist next we'll ask about pricing you can see the knowledge base will give us information about pricing and then it we adjust the variable count from one question to two and then we'll try one more time here we'll ask about any discounts we're offering and you can see it answers the question about discounts and special offers and then it recognizes that the number of questions is now three this if statement triggers and it takes us to this block so everything seems to be working just about normally now the last thing I wanted to show you guys was how to integrate with make.com and actually create some outside external action based on what happens here within the agent so that's what we're going to do right now what I want to do is if let's say a user does ask a question that's relevant to the business but it's not in our knowledge base and we're unable to answer I actually want to be notified about that notified of the question so that I can potentially add it to the knowledge base so that people who ask it in the future will have that information available so here's what we're going to do we are going to tab over to make.com and if you're not familiar with make it is essentially a platform for helping to integrate a bunch of different automations with different Services similar to zapier we're going to create a new scenario and we're going to set up something called a web hook a custom web hook a web Hook is essentially something that listens for some incoming information so that it can then push it onto wherever it needs to go we'll click on add a web hook the web hook name we can name it voice flow tutorial web hook and hit save and now you'll see this little icon running that it is listening for the data and and it'll determine the data structure from the incoming data so what we want to do is copy the address of this web hook to the clipboard so it's now copied we'll navigate back over to voice flow and here we want to set up an API step in voice flow so we're going to go ahead and delete this connection here after we say we're unable to find an answer to the question and we're going to go over to the dev menu and API and we'll click and drag that over here and if you're not familiar with all this the the HTTP methods get post and all that uh don't worry about it we'll go into it in more detail in a future video but basically when you're posting information you are submitting information to whever it's going if you're getting information you're trying to retrieve some information so since we're submitting the question the user's question we want to have that sent out we are going to change this request to a post and we simply paste in the web hook URL that we had before now you can set up a bunch of different information the headers the parameters the body depending on what your use case needs in our case we don't need any of that there's no authorization required or anything we just need a body and it's going to ask for a key and a value in this form data format here you can also choose these other formats we're just going to do the key value format we'll call this users question and the value we're going to set to be the last last utterance variable the last thing that the user said that resulted in the model not being able to create a valid answer so we've got the URL in there we've got the data in there in the body we're going to go ahead and hit send request before I do that I want to show you it's still listening for the request we'll send the request we'll enter in a value we'll say the user entered asked about if there was a deadline any deadline for our services let's just say that we'll click generate and we get the response this 200 response means it was an okay response everything should have gone well we'll navigate back over to make.com and you can see here now that the format has been successfully determined by that sample request that we sent so we'll click okay now that we've got that web hook set up we'll want to add a module to it create a connection we're going to scroll down we can you you have a ton of different options here we are going to use the email function and we will send an email and so when you get into this email section this is where you can connect the email address that you want to send it uh from I've just got my business address connected in there you can do that in the connection then you're going to set where you want to send it to we can just send it to the same email address you can see here that it recognizes the web hook has some incoming information the user's question that is the data that came in so you could set that if necessary as the email address we're going to go down here to the subject field we'll put in unknown user question and for the content here we'll want to go ahead and put in that user's question this is where the web hook comes in and that format the key and value you can simply select the user question and drag it over here and put it into the content and that's about it for our purposes here we'll go ahead and click okay and now we can click on run once to get the web hook set up to listen just for this one time we'll navigate back into voice flow we can actually resend the request because it's that question was fine we can simply resend the same request we'll click resend we'll navigate back into make and you can see we've got the green check marks which indicate it did receive something and it did go through to the email successfully so now we want to check that email address and see if it got the unknown question in the inbox so we'll navigate to my business email now and once we've refreshed we see that we have the users's unknown question we'll click it and all we have is just the question that I said is there any deadline to use your services which is exactly what we put in all the way over on The Voice Flow side now we are getting it on the back end to my own business email address so let me know someone had an unknown question maybe I want to add this to the knowledge base maybe I don't obviously you can customize this in a ton of different ways but this would be the general idea of how you can connect things in voice voice flow to things on the back end like a database or a Google spreadsheet or an Excel file or a ton of other things just whatever you need done this would be a simple integration you could do to perform it now we'll want to actually connect these blocks here and then in the case of success or failure if it failed for whatever reason it doesn't really matter we'll connect both of those up with this new block six just asking if there's anything else and that sort of completes the loop they can ask another question they can end the conversation but that completes everything so the cycle should work now and that's just about it for our super basic agent that we have built here you can do other things to customize it like changing the color of the different blocks depending on what you need it for obviously you can switch these around and make it look much more organized much more pretty much more streamlined that sort of thing but yeah this is just a base to get you the lay of the land of voice flows or how everything interacts how it flows together so you can understand what you can start building but by all means iterate on this improve on it expand I will copy this template if you want it into a VF file and put it in uh the description a link to it and you can download that and then upload this if you didn't want to start from scratch and once you're done the only thing left to do is to get this agent onto your website so to do that you'll simply navigate back to the main menu of the agent here you get down to integration here on the left hand side navigate to the web chat section and then you copy this snippet of code and you paste it on your website you can also customize how the agent's going to show up on your website you know where what it looks like that sort of thing you can do that here but that's it it's pretty simple I've done it a few times now and I haven't had any problems with it and my friends thank you so much for watching that is going to be it for today's tutorial I hope you got some good information I hope you enjoyed it if you did please like and subscri subscribe if you want to stay tuned for any future videos by all means if you have questions if you have comments for how I can prove if there's any projects you want to see done in the future with this or with other services please let me know in the comments below I appreciate you very much for watching you have a great rest of your day

how's it going everybody rob here just wanted to do a quick demo of the image labeling app that I whipped up really fast for my Tinder machine learning project just to give you a quick demonstration of how it works and how you might be able to use it for your own projects so real quick the reason for this app is because I downloaded a huge data set off of kaggle it was over 1.2 million images from Instagram but the images were all just random images they weren't all relevant to the purposes that I needed them for which would be pictures that you might find on a girl's dating profile so I wanted a quick way to sort through all the images choose which ones were relevant and then label them also all the while saving them in a folder as well as a CSV file and this app almost works like a Tinder in a way which is kind of interesting because I'm using it to build a Tinder machine learning program or model I'll show you how it works once you booted it up you'll get this real simple simple interface you'll select the image folder by clicking load image folder you'll select the folder with your images in it and then you'll get this interface here it's got the image and it's got a few options down below now most of the images in the data set like I mentioned are not relevant for my interest and in that case like this one uh you could just click next image it'll just basically skip the image go right over move to the next one you do this a few times until you get to an image that you think is relevant now this image definitely one you could find on a girl's dating profile so one that would be relevant to include in my data set for demo purposes let's just say I find these girls attractive I click yes to add them to the data set what that does it does two things we'll come to this folder here this is you specified in the code which I will link in the description below first it copies that image to the images folder you can see we have it here and it will also update the labels CSV file with both the image name and the label that I assigned to it so let's get out of this we will not save we'll go back we'll demonstrate one more image another picture you could uh expect to find on a girl's dating profile let's just say for demo purposes uh I think no no offense to any of those ladies but we're just showing the demo here we'll go back to image that image has been saved labels file name label and so you can see you can just go through this really quick now because it's more efficient and constantly moving your mouse back and forth to select the images I've binded some keys on the keyboard uh I think it's one is yes zero is no and just to load the next image you just hit the right d so you can real quick just go through tons of these obviously you would want to uh pay close attention to the images but let's say yeah so this is a image well let's just say this is an image a girl would put on her dating profile I'm not sure if she would uh we'll go ahead and hit we won't click it we'll hit one for yes you can see I didn't click on it there I just hit the one key but there it is it's saved to our images folder and this is what you do you can just go through these one by one now I do want to say I'm pretty new to the uh to machine learning I'm definitely a novice all I've taken is an a fairly introductory course and now I'm working on my own project to sort of hone my skills so I have no idea if this is uh really a good way to do it um I'm sure there are much more sophisticated professional and clean ways to do it but but for my purposes what I need for this Tinder project I thought it was a reasonably efficient way to do things so I just wanted to share it obviously you can modify it for your own purposes and if you have any questions be sure and let me know everybody take care

how's it going everybody rob here just want to do a quick video on an error that I've been getting when I'm trying to deploy my image classification model using gradio uh it's a model built with Caris on tensorflow and the problem I'm running into is I was initially running into is this error that you see here when you follow the guide It's the expected keyword argument shape when you're creating your interface here and then the image object uh it doesn't like this shape parameter the reason is because it is outdated as of gradio 4.0 the problem is that the guide on gradio still uses this deprecated parameter uh for how to tell you how to do it and that's why even in the guide when the demo should be launching down here it doesn't it just stays on loading this whole time uh if you go to hugging face and you find the image classif image classifier uh you'll see it's working just fine you'll see the image you'll see the uh version rather that it was running on is 3.44 point4 uh for this one whereas in the guide they're all the way up to four .19 so this code no longer works basically but it's still listed as the code in the guide on gradio so I was running into some problems getting this to work and really I still am I found the only thing I did to get it to work was to install just the version that you see there on hugging face in their GitHub code and when you do that and launch it it runs just fine but if you you just use the code as it said in the guide you get this error now I searched through uh various open issues on gradio GitHub page and I couldn't find anything related to this nor could I find anything when I simply just searched on Google so that's the reason I'm making this video I'm by no means an expert someone who's got a little bit more experience and knows a little bit more about programming could probably figure this out but really I just couldn't get it because here's the documentation for an image from version 3.5 you can see there's this shape parameter that lets you resize the image when it's pass to the function which makes perfect sense to me but when you change the version to 4.19 this shape parameter goes away and furthermore there's nothing that really seems to replace it Nothing fits as something that could reshape the image once it's passed into the interface and then when you try to do that you know even if you remove this argument so that it has no problem with the parameter itself you still get an error when you're trying to pass in your image because it says it can't reshape the image into the shape it needs which makes sense but then there's nothing either th here in the documentation or in the guide that would indicate what sort of you know the replacement for that parameter how actually reshape the image specifically with tensorflow that's that's the one I'm working with here so that's the reason why I made this video just to maybe help somebody else because I'm pretty new at coding and it didn't even necessarily occur to me to just roll back the verion that I've been using but that that fixes it you're using an outdated version of radio but you'll still at least get your classifier to work as you can see here you submit it and it generates the outputs so yeah I'm not totally sure what's going on uh perhaps I'll open an issue and see if they want to get the Guide updated because it's kind of annoying the reason personally I use gradio is because I'm not super technically minded yet I don't have a ton of technical skills I just wanted something to easily deploy my model and sure enough you know just right away I immediately run into issues trying to uh to deploy and had to spend some time troubleshooting but that's life I just wanted to post this video maybe it'll help one or two other people besides me and uh let me know what you think you have a good day

what's going on everybody my name is Rob WN and I help businesses unlock the power of AI with voice agents and today I'm going to show you something really cool it's going to be how you can run custom code in your make.com automations using a service called AWS Lambda now make.com is great for automations it's uh an excellent low and no code platform but with that setup the low and no code does come some limitations sometimes you need something a little bit more robust a little bit more involved some custom code so that's where AWS Lambda can come in and you can run these custom code functions in your make.com automations and have everything fully integrated so that's going to show you how to do today going to show you how you can set up the function in AWS Lambda how you can integrate it into your make.com flows and how you can test it out to make sure everything was working correctly so let's dive in so here we are in make.com and we're just going to use a super simple basic trigger for this one just going to set up some simple variables and what we'll do is we'll go ahead and add a Lambda function we're going to invoke a function but before we do that let's actually create our Lambda function so we're going to hop over here to AWS Lambda uh if you don't have a AWS account it's very easy to set one up you can go ahead and do that first but once you're logged in you'll want to navigate to the Lambda service and you'll come to this the screen where you have a list of all your functions and you'll simply create a new function give it a name select your runtime for this one we'll just use Python and we will create the function by clicking the orange button down here give it a second and that'll bring us to the function editor and if we scroll down a little bit we'll come to the actual code editor portion where we can Implement our code and set up our logic so if you're not familiar with Lambda each Lambda function has two parameters an event parameter and a context parameter the context parameter is sort of metadata for the function you can disregard that in most use cases the event is passed as a python dictionary it's a Json object and then pars into a python dictionary so that's how you access it so real quick I'll just write the logic for our particular code which is going to be simply adding two numbers together which we will pass from make.com as arguments into the Lambda function when we invoke it with that module so we'll just write this we'll just write standard python code and I'm getting these variable names from the make.com trigger module where I set them up I'll show you that in a second add them together and then we'll simply return the result now once you've written your logic you'll deploy your function by clicking the deploy and a good idea also is to test your function before passing any variables in make so you can do that by clicking test you can create a new test event for something simple like this we can simply keep this uh hello world format and then just rename the variable names with what we need our variables are going to be num one and num two and they are integers so we'll get rid of those strings and then you can click invoke to actually test the function and we can see the response is what we'd expect so our Lambda function is working correctly when we have a properly formatted payload so let's navigate back into make.com and we'll go ahead and add this Lambda module you'll set up your Lambda connection if you haven't already done so you'll click this drop down and find your function here's our demo fun that's the one we want invocation type is request response and then for the body you'll want to put this in Json format so we'll just type this out manually you will want to use double quotes here so it's proper Json and then we'll load in the variables that we set up in this basic trigger just like that close the brackets click okay and everything should be working correctly we'll go ahead and run this once oh I want to show you this basic trigger we just set up a couple of variables you can do this manually in here uh to get the ball rolling on this scenario and then we'll click uh run once and we've got got the output from our Lambda function it correctly added those two together and then if we wanted to we could go on and add more modules and use these Lambda outputs as variables in our next module and so on and it's as easy as that you have just learned how to run code in this case python iny make.com scenarios which can open up so many possibilities for custom Automation and make your flows much more robust and much more scalable and if you found this video helpful please give it a like if you have any thoughts or questions or comments please leave those in the comments below if you're interested in more advanced usages of AD Lambda go ahead and subscribe and follow because I will be posting more advanced use cases for this time type of Automation in the future other than that thank you for watching and have a great rest of your day

what's going on guys Rob win here today I'm going to be showing you a super simple way you can potentially increase revenues and customer satisfaction on your e-commerce store using a pretty simple configuration uh to create an e-commerce chatbot that can both recommend products and provide customer service functions to users who are visiting your site it's using an app called streamline connector in the shop of I store just wanted to go through a quick tutorial on how you can set it up get it up and running and get it working on your e-commerce door let's go so the first thing I wanted to do is just give a quick demo of what this thing can actually do so you can see here it's uh you've already started the dialogue with the agent it's asking you what you're looking for and they can type in just conversationally the user that is what they're looking for we'll just put in a stock message there they're looking for a laptop but they don't have a large budget and the agent's going to come back with not only this personalized text uh detailing some products and why it might fit their needs or what they're looking for uh it's going to give some details on the products in your store it's also going to provide this Carousel uh where the user can cycle through the options listed above and you can click on any one to take you directly to the product page obviously I don't have a product page because I haven't set that up but for your store you would and the other cool thing you can do is you can track the order status with this you can set it up so it'll ask for an email address we're going to enter that and give it a couple seconds and you can see it was able to find the order for this particular user uh gives you a picture of what they ordered a little link to take you to the order screen and show the exact status so that's the other cool thing you can do you can also set it up to be just a more General customer service uh knowledge providing you know FAQ type chatot but since that's pretty simple to do we won't specifically cover how to do that in this video this is mostly just going to be for how to set up product recommendations and the order Lookout feature so the first thing to do to get this set up is we're going to navigate to streamline connector's website I'll provide a link to that in the description below once we're here we're going to click on templates and then we're going to go down to this product and orders version three at the time of this video we'll click on that and then we'll scroll down here to where there's a free download link we'll click on that and what that's actually going to do is download a the or the template into your voice flow account so obviously you'll need a voice flow account already to uh get this started but we'll give that a couple seconds and once it's done importing you will see this Shopify streamline template now loaded in your agent section of your voice flow account next you'll want to navigate to your Shopify account and you will need an actual Shopify store you cannot do this with just a development store but once you're in your Shopify store you'll go down to the app section you'll search for the Streamline connector app and it should come up I've already got it installed so I'll click here you will need to sign up for a plan for the Streamline connector but you can get a free trial I'll leave a promo code in the description below to extend that free trial a little bit to give you a little bit more time to work it out and see if it's something you want to try in your business but once you've done that you'll arrive at this screen it says welcome to streamline and now we're going to connect our assistant we'll get this screen where it's asking for an API key in our chatbot name so to get our API key we'll navigate back into voice flow we'll go into this Shopify streamline template navigate over to the Integrations on the left hand side and then we'll copy this API key we'll navigate back into the Streamline app enter the API API key there give it a name and then we'll click connect so the first thing we'll do once we've got this streamline assist and connected to our voice flow agent is we will import the product information from our store into our voice flow knowledge base and to do that what you'll do is you'll click on these three dots here you'll click manage data you'll get the assistant knowledge base here with nothing in it currently we'll go up to create and then send products we'll give it a name you can select specific products if you want to we'll just send all active products I think it does that by default everything else we'll just leave as is which we actually have to do if we're using one of their templates and then we'll simply scroll down to confirm and save now what that's going to do you'll see the upload is in progress here if you navigate back to your voice flow agent and navigate to the knowledge base section we can actually see that now we have a data source in our knowledge base for our agent and this is what we just passed over from the Streamline connector app from our Shopify store if we click on this we can see on the right hand side we've got information about our products in my case I run a tech store I just created a dummy store with a bunch of sample products we've got Apple iPhone Samsung iPhones laptops Etc but you can see the knowledge base now contains the product information it's got the title of the item and then a paragraph with a description of the item as well and that simply matches if I navigate over to my Shopify product section we can see I have my list of dummy products here and each one has a description with details about the product that's the exact information that's passed over into this knowledge base now the next thing we'll want to do is navigate to the product recommendation workflow we can do that by going to workflows double clicking here and by the way if you're not familiar with how to use use voice flow I have a whole tutorial on how to use voice flow which you can check out just to give you a lay of the land and understand what's going on here but once we're in this workflow we're going to find this actual streamline connector function which we can click on here and you can see the Vari variable mapping over here and what this means is that it's taking certain values from our voice flow workflow and then inputting them into variables within the actual function itself and then here at the bottom the output it's the reverse it's taking what the function returns those variables and then loading them into variables within the voice flow workflow what this means for our purposes is that for this input variable for the VF API key we'll actually want to paste that same API key that we did before when we connected it to the Streamline connector so again just a reminder to get that we can navigate to Integrations copy this API key navigate back to the product recommendation page and paste it in the function in this value here now what the function actually does in plain English is it takes the user's question whatever their whatever details they give and it goes through our knowledge base of products that we just uploaded a moment ago and it finds the three most relevant products and converts them into a carousel a carousel is that thing you can rotate through by clicking the arrow it'll show you a different product it shows the picture the title the price maybe a little description that's a Carousel and this function creates that Carousel based on the user's question for our purposes here I'm going to remove these links to this modify payload artificial intelligence step because we're going to be putting in plain emails we don't need to have that modification step there we'll just go straight to create recommendation and then we'll also want to modify this prompt here this is just the default prompt from streamline connector you'll want to adjust this with your own prompt relevant to your own store I'll include a description of the prompt that I'm going to use in the description below that I think is a little bit better than this one and you can modify that one to suit your own purposes so now that I've updated the prompt with something that suits my use case a little better I'm also going to adjust the prompt settings first off I'm going to change the model the default from streamline is this Claude 3 Sonet model which is quite an expensive model I've tested a few models and even the cheaper ones are performing pretty well on this task so I'm going to change it to just Claude highq and that seems to be working fine and it's the cheapest model here on voice flow and this is a good opportunity to remind you all that in large language model prompting tokens are money so if you don't have to spend tokens unnecessarily you should always look to reduce your token consumption by using the cheaper models we're going to set the temperature down to 0.10 give it a little bit of wiggle room but nothing too crazy and Max tokens I'm going to set at 600 like I said I've tested this a few times and it seems to be working fine at those settings and we'll also just adjust this system message you can tailor it to your particular brand I'm going to put in just a generic text store system message here all right now the next thing we're going to do is actually go into the function code and modify the code just a little bit nothing too crazy so don't get scared do this we'll navigate back one step and then we'll actually go down to the functions and we're going to be taking a look at the product recommendation function and the first thing to take a look at in line 16 is this chunk limit now I want to point out that you don't have to make any modifications here it depends on your use case but for me six chunks is too much that basically results in six products because my store is smaller a lot of those products ended up being irrelevant to the user's query so I'm going to change this down to three which is what streamline originally had it as in their past versions of this template but they bumped it up to six for whatever reason I'm going to change it back down to three just because it fits my store My Demo store a little bit better you can do whatever you'd like the other thing to potentially modify in this code if you scroll down a little bit to line 78 is this body text length this is referring to the item descriptions so if we navigate back to my products page this description here this trimmed body is only going to take the first 280 characters of that description if it's over that amount and potentially depending on how large the descriptions are for your products this could cut off some very valuable information that you would want the function to have access to so that it can recommend the best products for the user so depending on how long your descriptions are you may want to modify this I found for my description bumping it up to 600 seemed to be a good amount it prevented it from chopping off some relevant information that would help the model find the correct products but again for this you can do you can try out different levels and find what works best for you and that is actually it for setting up the product recommendation system we can now tested make sure everything's working correctly we'll navigate back to the product recommendation workflow we can start the test from this block here we'll want to train our agent first to make sure everything's up to date now that that's trained we can restart the test and we'll put in our message we'll say what we're looking for and any details that we want to include we'll submit our message and let the recommender do its thing and we get a response that was pretty much in line with that demo that we did at the very beginning all this Json text in here is that Carousel object that was created by the function and then this response is the large language model's response to our question combined with that Carousel and product information that it got from the knowledge base you can see how it personalizes the message to what we said and even in its product descriptions it recognizes that we said we don't have a lot of money you can see how it says you know while it's not the cheapest option uh this one is a bit more expensive but it's still a great choice Etc and then at the end it actually prints out that carousel with the items themselves you got a nice picture and a link where you can go to shop now and you can also navigate through the three options this is where those chunk limits come into play if you wanted to add more products in this Carousel you could do so by adjusting that chunk limit and of course by clicking on that shop now link it's going to take you to the product page on your store's e-commerce site I don't have anything for mine because it's just a dummy store but that's how that would work so the next thing we'll work on is this order status lookup feature of the Streamline connector app that also can be really helpful when you have an e-commerce store customers are coming on they want to check the status of their order see where it is that sort of thing so first we'll go to your Shopify store and you want to actually make sure you have some orders that it can pull information from and assuming that's the case we'll navigate into our streamline connector app we click the three dots we'll click manage data we'll go back up to this create option and this time we'll click send orders and all we need from this page we don't have to worry about anything below this we'll just click copy for this end point here at the top we'll navigate back into voice flow we're going to navigate back into the functions that we were just taking a look at this time we'll look at the order status function and what we want to do here in line 17 you can see right above it says paste the endpoint we gave you inside our app here in between these two little marks we're going to paste that endpoint that we just got from the Shopify app just click anywhere away to make sure that function saved we'll navigate back into the order status workflow in here we're going to remove this link to check if it's a valid email because obviously we know we're going to be inputting a valid email but it is something you may want to have in a production AI system just to make sure that the user is putting in an email that actually works again this is just going back to that principle of not using tokens unless we really have to so since we're just testing here we're not going to send a request to the large language model we'll connect the capture step with the retrieve order function and that should be it we can click on this button to start the test here going to ask for an email address this this will correspond with an email address for one of the customers in your orders page I just set up some sample orders from my store with some sample customers and this is the email address for the most recent order so we're going to search for this one and you can see that the function was successfully able to pull this order this order 104 from my store and of course if you click on view order it's going to pull up a page with detailed information about the order and folks that is pretty much going to be it for this tutorial like I said earlier you can also set this up with just a general knowledge base FAQs store information your store policies things like that to create just a general question and answer chat bot but that's fairly straightforward to do uh I covered it in my last voice flow tutorial video there's also a bunch of other videos on YouTube that you can search to do that as well so this was strictly about using that streamline connector app to import the product information and provide recommendations within the chatbot interface and also to look up order information and pro provide that that order status that the customer might be looking for and like always please like this video if you thought it was helpful Please Subscribe if you want to stay tuned for more videos if you have any questions or comments about this or other topics related to AI automation feel free to leave them in the comment section below uh my website is val.com if you want to work with me you can please reach out that's it for today's tutorial thank you all for watching you have a great rest of your day

hey guys my name is Rob win and for the past couple of months I've been taking various large language model prompting courses so that you don't have to because today I'm going to be distilling everything that I learned into one simple easy to understand video with the most relevant bits I'm going to take you from zero beginner not even knowing the fundamentals of prompt engineering all the way up to ready to start iterating at with advanced level prompts in your production level application so without further Ado let's get into it oh and I just want to mention guys while I doing encourage you to take notes throughout this to really help with your learning I will include a free study guide that includes everything we cover here it'll be in the description below all right so first things first prompt engineering fundamentals what is it and why is it a thing so you can see here on the screen prompt engineering the definition is the practice of Designing inputs for ai ai ai tools that will produce optimal outputs and this goes for large language models it goes for image generation models goes for any sort of generative model where the better the prompt the better the output and so there's there's been this sort of Art and Science that's developed around making the prompts as good as possible to get the best outputs from the model that practice is known as prompt engineering and got a couple images on screen that I thought were interesting to take a look at first one go over on the right it's that funny uh it's all Ohio meme if you've seen it before on the internet and it's talking about how each progression as we've gone over the years and gone through the different eras of coding languages they've all been sort of abstractions up from the basic zeros and ones that's it's all eventually converted down to to actually communicate with the computer with the machine and it's been the Holy Grail The Dream the fantasy sort of since the beginning of computer science since the beginning of computer programming going all the way back to like those little Punch Cards they literally used to feed into the machine a to love lace and all that to be able to just tell the computer in plain language what you want done and what you want it to do that's been the fan that's been the dream and with these large language models we are sort of getting to that point you can see the tweet from Andre karpathy he's a famous computer scientist the hottest new programming language is English and that's because with these powerful models like chat gbt and others you can simply tell them a lot of times what you want done and it will be able to create a program with that functionality and not just creating computer programs like it will be able to do all sorts of things obviously it can generate images obviously you can analyze Excel spreadsheets create uh you know pie charts and graphs it can do all sorts of things that previously would have taken a very select skill set set to do it's not all the way there the functionality is pretty Limited at the moment it's it can do basic to inter intermediate stuff fairly well for the more advanced stuff usually a human will have to go in there and troubleshoot modify some things and sometimes of course it just gets it flat out wrong and you just have to do it on your own but we're slowly getting to that point in the key is with prompt engineering with a well-crafted prompt you can replace hundreds of lines code and in a lot of cases even the need to learn to code you don't really need to learn a programming language if you want to do fairly basic stuff or in the past even to do just simple things in Python you're probably still going to need to spend some time learning the syntax learning the basics like objects and classes and you know the various operators and in that sort of thing but with prompt engineering now with good prompts you can just tell the large language model to do it and it will take care and that's important because it frees up so much human energy to focus on other things to just continue this cycle of improvement and refinement and just continue the progress of Technology basically but you can see here on this screen in addition to replacing hundreds of lines of code a good prompt can also just vastly increase the accuracy of the responses you get then if you just fed it like a basic Google search type response it can also this is a big one effectively fine-tune your model to your specific use case so normally with fine-tuning you would have to go out uh get a bunch of data label a bunch of data validate it with you know either humans or other models more powerful models going over it and then you would have to train the model on it you'd have to test it evaluate it see how good it is that is a very timec consuming and expensive process and it's been found that with good prompts and specifically good examples that you can provide to the model that it can effectively fine-tune it pretty much it it can understand what you want done and it will tailor its responses to what you want and it can fine-tune it that way so a massive time save there with good prompting and then the last item there it can squeeze more juice out of the cheaper models like 3.5 chat gbt 3.5 for example and give it the performance of you know not obviously not fully the the latest model but it can improve it enough to where you can use the 3.5 in your applications and it's good enough to where the application makes sense and is scalable because the cheaper or the mo the latest models are quite expensive the earlier models a fraction of the cost so if you can squeeze those cheaper models and get them to perform you can save tons of money and your business or your application us use case can actually make Financial sense so that's another reason uh some use cases for large language models and the importance of prompt engineering within those use cases specific knowledge chat Bots and potentially voice agents with a well-crafted prompt you can utilize these for service tasks when people go to your website uh if they're trying to track their order if they want to return an item or track the return you can use these models and the inputs from the customer to essentially handle all that and just free up tons of Labor to focus on other projects you can see lead generation appointment setting all all these tasks that often times will require lots of human input for things that they just they can be automated fairly easily you can with good prompt engineering and with a suitable model you can just automate these and drastically reduce the cost cost for your business and for your clients on the right here is a picture of a NASA chatbot that Nasa uses it's called badara it is a like a biology and biomimicry specific chatbot and the NASA employees will interact with this chatbot as they go through their workflows and it's tailored specifically to the badara process it's this whole thing biomimicry is where you you model you model model structures and systems based on the patterns and anatomies you see in biology it's super interesting but you can see even Nasa uses prompt Engineering in this way to create like interactive chat Bots for their employees here we're going to go over just the types of large language models if you haven't seen these before it can be quite confusing to understand what's what what's a model what's a chatbot uh what what's open AI versus chat GPT Etc so hopefully this image will break it down at the top layer here you have the the models themselves these are like the code the weights all the the parameters of the neural network this whole massive just just data and GPT through open AI That's the model Gemini through Google that's the model and also the chat bot the name of the chatbot that you interact with Claude is the anthropic model that's also called Claude and then llama is the one that meta came out with which is open source the chatbots are a userfriendly wrapper on top of the model so that you don't have to interact with the model via code you can just type it in in your web browser and then it will send it via code to the model so the chatbot is chat gbt Bing Gemini those are just so you can type in it's super userfriendly and you don't have to worry about getting into all the code and interacting it with python or whatever and then there's task specific models which are fine-tuned like we mentioned earlier fine-tuned versions of Prior models where this one's GitHub co-pilot it's code specific Jasper has been fine-tuned for the copywriting task Amazon has built one that's another code whisper that's another code specific one there's all sorts of these for specific tasks that have been fine-tuned versions of the various models so that's sort of the lay of the land all right so the next thing we're going to go over the next fundamental is tokens what are tokens they're basic basically words the language model can't understand words it has to break them up into numbers or get the input as numbers so what the model will do is it will break up your input into words one token equals approximately 3/4 of a word and it will then convert those tokens into numbers and feed those numbers into the model it's pretty self-explanatory from this picture here the paragraph is broken up colorcoded into the different tokens you can see they are then converted into words for example this comic here the third entry in the sequence is token number 11 and you can see 11 at various points throughout the text here because there's multiple commas in this paragraph obviously there's tons and tons of different tokens that's why they go to up into the tens of thousands they go into into the hundreds of thousands and this is how the machine can understand your words by breaking into tokens now an important thing to notice is that less tokens is going to equal a cheaper system so in general you should always aim to make your prompts and your inputs as short as possible while still maintaining the accuracy and then also there's going to be a tradeoff potentially with the number of tokens versus the accuracy for example if you find that you can get 98% accuracy with 100 100 token prompt or you can get 100% accuracy with a th000 token prompt you have to sort of consider is that 2% difference in accuracy going to be worth those extra 900 tokens and all the costs that that are associated with it that'll depend on your use case you have to experiment see what you can tolerate but that's another thing to keep in mind next is going to be the system message the system me message is basically the North Star for the model it's always going to reference this whenever it's answering any prompt the you are helpful assistant here at the top that is the system message for chat gbt so whenever you input any prompt into chat gbt it first checks that system message says okay what who am I here what what's my role how should I frame this response what's the relationship between me and the input that sort of thing it's it's kind of funny you can go into the playground the open AI playground and modify this and say things like you are a massive jerk or like you're a total and it'll it'll formulate its responses to to reflect that and it will answer in a not so kind tone but the basic one is you are a helpful assistant this is similar to we'll go over later the role in Persona that you can input as part of the prompt framework uh but this is this is like one level above the role in Persona that you actually input in the prompt itself this is like embedded within the prompt and with chat GPT you can't even change this you can enter custom instructions which are again like a a sub system message but it's Main primary assistant message is always going to be you are a helpful assistant and uh this you are badara a biomic designer and research assistant that's actually the was the system message for the NASA chatbot that we saw earlier just explaining the role explaining what they're good at how they operate that sort of thing so you can get an idea of how it could be used in an actual application like that chatbot all right the next fundamental we over real quick this is temperature and this is essentially the randomness of the outputs that you get from the model the default is chat GPT or the default is one with chat GPT and what that means is when you put in the same output in the chat GPT you're not going to get the exact same output every single time it'll be slightly tweaked slightly randomized little bit different order a little bit different wording maybe a little bit difference a little bit of difference in the ideas that you get and that's usually what you want Chachi to to do to sort of come up with unique and creative ideas you can increase the randomness by increasing the temperature although if you go all the way up to level two what you'll find is you'll get is the extreme it's just like random gibberish It's So Random and then if you go all the way down to level zero it's actually the opposite it's completely deterministic and predictable it's always just going to pick what it deems the most probable next word in the sequence so you can imagine for for a production or business use case where you do want it to be S you want the same input to generate the same output if multiple customers at ask the same thing you wanted to give the same response if the same customer asks later what's you know the same question later you wanted to give it the same response so in those cases you would want to set that temperature down to zero to make it very or quite deterministic and then we have top P which will only consider words over certain percent percentage probability so you could set this to say 20% and it would only consider words that are over 20% for the next word so if the ne it has a whole list of words that it could be the next word but only dog cat and horse could be over 20% it says those are the only ones that have a 20% and we'll only consider those three words next three words in the sequence and generally you'll want to use either temperature or top PE in your apps you won't want to use both the next fundamental is delimiters you've probably seen these before delimiters really anything that breaks up text into a easierto read format even things like commas and periods and spaces and things like that are technically delimiters usually you'll see them in this markdown format with the number sign or asterics or underlines things like that delimiters are great because they can break up up the prompt so that it's much easier for you to read and generate and modify and also these models were trained on a lot of text that contained the limiters so they can understand them very well they can recognize sort of exactly what's going on when it sees them it's not going to confuse it so it's great for us it's good for the model it's just a win-win to use delimiters to break up your prompts and we'll see some examples a little bit later in the slideshow of how you can use these in prompts this this would be like a like a very basic template that you might have seen before in markdown format uh the next thing I want to go over is rag or retrieval augmented generation this is more of a like a technique but I wanted to put it in the fundamental section just because it's so it's become so ubiquitous over the past year or so to utilize this this retrieval augmented generation with models and what this does is it will go out out to some external Source find relevant information and then incorporate that information along with the user's query before it feeds it into a model so you've probably seen or been aware that jgpt has a knowledge cut off of a certain date this is a huge problem because if you're asking about things that require recent knowledge it's it can't really help all that much this is where rag comes in because what it can do is it can go out find relevant information via a tool via an interet internet search with Bing or Google get the relevant information that it needs combine that with the user prompt and then output give the output to the user doesn't have to be an internet search either can also be utilized with a knowledge base for let's say a specific company has a knowledge base that they want their model to pull from when it answers customer requests it will go to that knowledge base find the information that it needs needs and then answer the customer request with that knowledge it improves accuracy and reduces hallucinations previously if you asked it something about knowledge that it didn't have in its knowledge base it might just make something up obviously now that by giving it a specific knowledge base and the ability to go access that it's going to reduce that and then the final benefit is the knowledge base can up be updated and kept current over time and obviously internet searches can be kept current over time time as well and finally the last fundamental I want to go over is iterant iter iteration and experimentation prompt engineering is very much a Cutting Edge discipline we're still on the frontier here there's new techniques and new methods being discovered all the time most of the ones we'll go over in this presentation have been discovered in the last year or two super recent you might find something literally yourself that works better than anything else that's been discovered and start utilizing it and make it known make it make it a new technique that people start using the point is experimentation is key here you don't just want to go with the one prompt and call it a day you want to iterate see if it your prompts get better get worse what I'm going to teach you in this the rest of the slideshow is the framework and that's just the starting point you'll want to iterate from there try it out see how it works and eventually you'll sort of dial in on what techniques work best for your specific use case all right so now we are going to get into the meat and potatoes of this video The Prompt engineering framework and you can see on the left hand side there the six components of the framework the role the task the specifics the context examples and any final notes that you want to add now the framework is definitely just guidelines it's more what you call guidelines than actual rules you don't need to do every single part of the framework for every single prompt you don't need to put them in exact order you can combine them you can leave some out etc etc in fact the vast majority of prompts you've done in your p in the past if you use chat GPT probably haven't included this entire framework you just had one or two in there and it worked mostly just fine this is for you know getting really accurate resp respones you really want to dial it in and get the most the best outputs from your model in these production use cases for the more complex tasks like that you will want to abide by this framework and utilize it as far as building out your prompts like I said it's you can modify some things here and there but you will want to use it as a guide so first up roll SLP Persona we've seen it called both things this is where you simply tell the model what's going on just one to two sentences who is it what's it good at what's its role this is you are an expert YouTube video creator you specialize in making videos that are informative engaging fun interesting that sort of thing you are an expert car mechanic with 50 years of experience you specialize in working on foreign foreign makes and models that sort of thing you're telling the model what it's good at it's a world class expert at whatever your task is done and whatever specific attributes you want to have for your task that you'll want to include those key qualities as well if you want your videos to be professional you know clean cut very informative you'll say that if you want them to be funny engaging that's you'll want to include those here tell it what tell it what it's good at the next component is the task and this is basically just what you want the model to do this is the most basic element of any framework you pretty much need it in order for your prompt for the model to do anything or create any sort of output the task is the one you where you'll need to have it pretty much no matter what and everything is sort of built around that it's best to start with an action verb in these you know uh create generate analyze write things like that it tells the model specifically what you want done and as you can see there you want to be specific direct and succinct tell the model exactly what you want done use specific words but don't go overboard you don't want to be frivolous with your tokens both due to cost but also because using excess tokens in this area can actually confuse the model and it will try to do too much at once it won't be dialed into specifically what you want done so keep that in mind when you are building your task all right so now we'll go over the first technique of the presentation it's called Chain of Thought prompting and basically what it is is it's where you break down to the model exactly the thought process that you wanted to go through so so the image on the screen we have here is an actual excerpt from the paper that popularized this technique on the left you can see in the examples it gave the model it just said the answer is 11 but on the right with the example breaking down the math it gave it a step-by-step process proc for how to it came to each conclusion how it came to the answer and when the model was fed these two different examples the one on the left that just gives the answer couldn't quite reason it out it got the wrong answer whereas the one followed the stepbystep train of thought process exactly and it got the right answer in that case so we can utilize this in our prompts it can be utilized both here in the task section of the framework also potentially in the example example section when you're giving it uh the format and things like that you want it to follow you can also throw in some step-by-step processing as well there but it's important to just understand that when you break down the exact thought process you want the model to follow accuracy a lot of times can be boosted so it's a good technique to have in your Arsenal like you can see here it says or it's for tasks that require multi-step reasoning which a lot of the tasks you'll be using are more complex in the uh when you're you're doing for like a business application they're going to be more complex have multiple steps it's more much more effective in those types of situations it follows the format where you just want to say first step we're going to do this and then we get this with that we're going to do this and then finally do this etc etc like you saw in the previous slide now an interesting thing is doing that ideally or I mean breaking it down into the various steps might be ideal and might something you want to do depending on the use case but again token consideration is a thing and to limit tokens what you can consider is using this phrase let's think step by step at the end of your task this will tell the model or encourage the model to do this stepbystep analysis while also not needing to utilize the tokens of a much longer step-by-step prompt this has been found to get most of the the benefits of specifically you know detailing out each individual step you want so I would encourage you to try both out see which one works better see if one works much more than the other and see if it's worth those extra tokens or the extra work it takes to generate a step-by-step process for the model the next component of the framework is going to be the specifics section and this is where you're going to list out the most important notes for the task the additional details of the task so you can see an example here for the task is creating a script for a YouTube video in specifics you provide the details that you want between 3 or 5 minutes run time and to include at least one reference to the movie Pirates of the Caribbean whatever you want whatever for your your use case list format you usually works best for this section and you want to start small start with one or two items see how it goes you can add more if you need to uh if the model's not quite doing what you want again iteration is the theme here all right so the next item in the framework is going to be the context this is basically you want to make clear to the model what environment is it operating in what part of the business is it functioning in what type of customers is it going to be dealing with even things like what are the company values uh things that are important to the company stuff like that so it can better understand understand where it falls in the process better formulate its responses with specific language specific formats knowing what customer it's going to be talking to it's going to be talking to angry customers who uh are returning an item that didn't work or is it going to be talking to is it going to be people who are interested in the service and it's like a lead generation chat bot or that sort of thing giving it this context will better it will produce better responses uh for that all right now within the context portion of your prompt one of the techniques another technique you want to consider is this emotional stimuli otherwise known as emotion prompt these are phrases that stress the importance of the model's task they make it stress the importance of getting things right and you can see here on screen a bunch of examples taken directly from the paper that talked about this technique things like this is very important to my career things like you'd better be sure remember that progress is made one step at a time stay determined and keep moving forward other things you can use is this is vital to the business if you don't succeed in this task the business will fail things like that that really stress the importance of the task now why does this work you can see the bottom portion of the slide here this input attention attention is essentially how much how much Focus the model puts on particular words with the original prompt with no emotional stimuli this is the default the Baseline but when these emotional stimuli were added the model actually paid more attention to the important words in the previous sentence or in the task in this case which is just I think absolutely fascinating because it's it's exactly how a human would act obviously these models don't have emotions in the sense that humans do neurotransmitters and hormones and all that and yet when you give it an emotional stimulus like was saying this is so important to my career please please get it right it still does the exact same thing a human would do where it pays more attention to the task and it's it's essentially gets more focused on the task at hand which Super fascinating how that all works but the important thing for our framework is that by including this language you can get the model to pay even closer attention to the important parts of the task and therefore increase accuracy which obviously when you are prompt engineering accuracy is going to be a huge huge uh piece next part of the framework is going to be examples uh the first bullet point you might have seen these terms before zero shot one shot and few shot it's really simple zero shot is when you give a task to the model with no examples one shot is when you give a task to the model and it includes one example as far as how you want the format uh or the input and the output to look like and sound like that sort of thing and then F shot is simply two or more examples that's all it is it's very simple you'll see these show up in other contexts but that's all it means zero examples one example or more than one example examples are uh very important part of the framework because you can effectively fine-tune the model with really good examples this is known as in context learning we talked earlier about how fine-tuning can be very expensive but with examples good prompt engineering and in good examples you can essentially fine-tune the model for your specific use case and get it maybe not all the way as if it was truly fine-tuned but get it close enough to where you don't need to go through all that that laborious process of actually fine tuning the model you can also I skipped one here you can also uh specify you know the format the tone the length that you want the answers for for instance a lot of times when chpt will will produce an answer it will say you know the answer is 25 often times you'll just want it to say 25 with no additional text that's where you can use these examples to great effect to really dial in exactly how you want it to sound and look when with examples you will want to use ideally the toughest most ambiguous example because what that does is it allows the model to formulate its decision boundary if you're familiar with that term in machine learning where is the cut off for classifying one thing this way versus the other if you give it if you give it uh con like curveballs like confusing examples ambiguous ones and you give it the right answer that you want it will have a much better idea when it uh encounters those examples in the future but that being said if you don't have those examples examples readily available you can just give it the input and output format that you want often in just a Q&A format we'll see some examples of that when we when we actually look at the full framework in action but you can just get by with just using basic input and output that'll still tell exactly how you want the answer formatted it'll tell you exactly how like long it you want it to be that works just fine and then how many examples should you provide in your prompts the re Research indicates that going up to 20 there there's improvements and accuracy going all the way up to 20 examples and then it it really starts to level off but for most use cases both in a just a labor sense coming up with that many examples can be time intensive especially if you have if it's a longer like a more complex task even just coming up with one example might be quite take a long time and then obviously the tokens if you're providing 20 examples and the examples are quite long that's a massive amount of tokens for just one input and we already talked about how to more tokens equals more money so if we want these to be scalable if we want them to make Financial sense in production applications you want to limit the number of tokens so that being said usually three to five you can start there and see see the accuracy that you get 4 to8 is like the where you get the the best rip bang for your buck but I would start with 3 to five see how it does and you can you can add more if the the number of tokens your token constraints allow it and if you see are going to see noticeable increases again you you'll just have to iterate and see what you get but start with three work your way up and see see how it goes and then the last part of the framework is going to to be the final notes section this is where you reate reiterate the most important parts of the prompt and it's based on this uh this phenomenon known as The Lost in the-middle effect that has been found with large language models and also with human beings not surprisingly where we pay more attention to things that are at the beginning and the end of our input for instance with this presentation you probably pay you probably have better recollection and paay more attention to the very beginning and when we get to the end you'll probably have a better recollection of the things at the end all the things in the middle can get a little bit lost and machine learning or language models work the same way they can sort of lose information that's in the middle so this final note section is where you want to reiterate the most important things maybe in the task section in the specifics just to really get it clear to the model that these things are important and to make sure it doesn't forget this image here is actually uh from the research again you can see that this purple line is when the large language model was actually given the answers to the query in the prompt and information gets buried so heavily when it's lost in the middle that it actually performed worse when it was given the answer then when it was not given the answer when the answer was buried in the middle of the documents it was provided that just shows you how how big of an effect this loss in the- Middle effect is and like you can see here there's also uh other things like formatting notes just negative prompting that's where you tell the model to do not do this certain thing you want to reiterate it here quick note on negative prompting you will probably see better results if instead of saying do not do this you actually frame it in a positive way like refrain from doing this refraining tells it to it's it's a positive version of the Do Not verbiage they've seen slightly better results on that with the models all right so now we are just going to quickly go over what some example prompts look like full prompts when they're actually you know typed out not going to read all these to you can pause and compare if you want I I wanted to make them a little bit different with the names like this is role this is persona for the first component of the framework the delimiters are different the the list formats are different uh examples are this one doesn't really have any this one has the Q&A example section things like that to show you that there's a lot of flexibility with how you can con conru these prompts but this is the general framework you're want to shoot for and once you have this framework like this might be the first iteration of the prompt and then you'll see what response you get and then you can iterate from there so yeah feel free to pause the video go over these this is what a the full prompting framework looks like when it's all spelled out all right next I briefly wanted to go over some additional prompting techniques that you may not utilize but I think it's good to be aware of them for when you're looking out at the literature that's available or you're looking through other prompt engineering guides you have an idea you've encountered these before and you know what they are so we'll go over this image first on the left here we have our basic input output prompt which is just where you give a basic query or task to the model and it comes out with its output it's super basic it's probably what you've done tons of times already with the models to its right we have the up upgraded version of that the Chain of Thought prompting where you encourage the model to think step by step or you alternatively you can spell out the exact thought process that you want the model to take we've gone over that one as well next we haven't talked about this one this is a technique known as self-consistency with Chain of Thought So c-sc you'll see it formulated as and what this is basically is running Chain of Thought multiple times and then taking the majority vote of those results and that's your answer so it's certainly even with Chain of Thought prompting it's certainly possible that the mod model is going to come back with an incorrect result if you're just doing it one time to combat that self-consistency will run it multiple times and take the majority vote assuming that it's not going to get it wrong a majority of the time it's certainly possible but doing that even further reduces that chance and therefore incre increases consistency to its right on the other side of the dotted line is an even more complex technique known as tree of thought prompting and what this does is because Chain of Thought prompting and even self-consistency are known as greedy where they will just go to they'll take their current thought they'll go to the next one whatever they deem most appropriate they'll go to the next one by the time they get to the end even if there's no great Pathways forward from its prior thought it can't really backtrack and go back to the beginning and say okay we should probably take a different path here it'll just sort of continue on the path that is going and produce the best result result that it can even if it's not the optimal one tree of thoughts can combats this by encouraging the model to if you're familiar with uh data structures and algorithms if you've ever dabbled in that there's these things called breath first search and depth first search their search algorithms it's very similar to that or if you're not it's basically just going through a maze where it'll go down this particular pathway let's say these green ones represent valid or or good thoughts that it wants to keep pursuing it'll go down here but once it reaches this thought it will say okay there's not really any good next steps from this one let's go back to the beginning and try an alternative path just like you would if you were U exploring a maze or going you know like a a cave Explorer or something like that and then it'll try a different path it'll find a route through the it likes better than if it just with original Chain of Thought prompting once it got here because it was greedy it can't really go back it would have to pick one of these two suboptimal options and that would be your output with tree of thought prompting you can actually back up and encourage the model to try a different path until it finds one that it thinks is is better so that's tree of thought prompting that's an improvement on Chain of Thought prompting just like self-consistency was and then we got two more techniques that you'll encounter and use react prompting stands for it's short for reasoning and action prompting so if chain of thought prompting is encouraging model to go through its thought process react is an addition onto that by encouraging the model to in addition to explaining or going through its thought process going through its reasoning and its actions and what that looks like in practice is it encourages the model to not only explain its thoughts but explain the action it took and then what it now reasons about that new situation before moving on to the next stage in the process it's like thought action and then it's reasoning or observation about the new state of things and doing that can even further add on in uh accuracy to Chain of Thought prompting and then finally with prompts chaining this one you probably will use quite extensively in your applications and when you're using it for your business use cases because you can use the output from a prior prompt and use that output as the input for the next prompt in my future videos when I'm going over you know how to build chat Bots how to build voice agents things like that I will go over exactly how that is used in practice but just be aware that it's definitely something you can do where you sort of chain these prompts together and fit them all into one cohesive system and it's better to do it that way a lot of times because it can be much easier for a model to focus and perform one specific slightly narrow task and then take that output and put it into another slightly narrow task then to give it this huge input where it's just trying to do everything and then taking that output and it just gets confused with all those tokens with all these keeping track of all these different inputs a lot of times it's it's like um it's like if you're familiar with decoupling applications in general when building out your systems you can decouple the prompt to each prompt in output is a specific function you take that output put it into the new function it's it's that sort of thing so in summary just going to go over the key points here to make sure everyone's on the same page a good prompt can replace hours of work hundreds of lines of code and even negate the need for a larger better model and even negate the need for for knowing code knowing programming in a lot of cases it's great A lot of these a lot of these models and chat Bots and agents and uh now other things like that can all be built with no code tools just through good prompt engineering it's great uh again remember that prompt engineering is still cutting edge and everything is still being tinkered with being developed new techniques are constantly being discovered URI could be tinkering experiments doing our thing and discover a a whole new technique that that works great and better than anything else that's been discovered still very much the frontier here which is super exciting and the framework that we went over remember it's just a guideline you do not need to adhere to it 100% all the time just use it as a framework just use it as a guide for how to build your prompts and iterate iterate iterate said it several times now but yeah iteration is going to be key your first prompt is never going to be your last one in terms of accuracy you always want to experiment and see how you can get the most out of your prompts all right guys that is going to be it for this tutorial on prompt engineering I hop you learned something if you did please like this video feel free to share it if you know anybody who is interested in making their prompts better and subscribe to this channel if you're interested in more content I'll be coming out with a lot more regarding building out AI automation tools uh how to AI first your business chat Bots voice agents all that going to be doing it on this channel in the coming weeks and months so subscribe other than that thank you very much for watching you have a great rest of your day

how's it going everybody my name is Rob win and this video is going to be about aspect-based sentiment analysis specifically how you can do it with the current as of May 2024 state-of-the-art language learning model instruct Absa now most of this video is going to be about how to use the instruct abso repo and how to get the model excuse me up and running so if that's what you're after feel free to skip ahead to the relevant part of the video but first I did just want to briefly go over ask ECT based sentiment analysis what it is why it's useful and how instruct Absa comes into play so we're all familiar with customer reviews for products we see these all over the Internet you can see some on your screen right now and they frequently have star ratings attached now General sentiment analysis which you've probably heard of would look at some text do its calculations and figure okay this piece of text seems like it's generally positive or generally negative and while that might be useful for some things it's not so useful for customer reviews because as we said reviews usually have star ratings attached and the star rating essentially tells us already what the overall sentiment is if it's four or five stars you can guess that the overall sentiment is going to be positive if it's one or two stars you can guess that the sentiment is probably going to be negative so what is a business owner what are they supposed to do if they want to get more detailed analysis on their product or service what if they want to know why people are giving positive or negative reviews that's where aspect-based sentiment analysis comes in because with this type of analysis as its name suggests you can dig into a review on a more granular level extract both the sentiment as well as the the specific aspect that is driving the sentiment so it won't just tell you this review seems positive it will say it will tell you these are the aspects that are driving that positive sentiment and also if there's negative sentiment in there it will tell you what aspects of your product or service are driving that negative sentiment so we can see on this Amazon page that Amazon has actually started doing this I want to say in the past year or so I'm not sure of the exact time frame but they have extracted various aspects of the product and assigned a sentiment classification uh to each aspect and that's what these little green check mark check marks mean if their model detected a trend of negative sentiment toward an aspect it will get a little orange negative there's none of that here with this product ones that don't have either a green check mark or a negative are considered neutral and this is what instruct Absa allows you to do so now I'm actually going to switch over to our hug hugging face space this is a space I created that hosts a fine-tuned version of the instruct Absa model you can enter in a sample review sentence you can and hit submit so we'll do that now and then it will return the extracted aspects as well as their Associated sentiments like this so you can see for this sample sentence food was extracted with an Associated positive sentiment the service was also extracted the other aspect with a negative sentiment and that matches the sample input sentence that we had here so that's the idea now obviously this would be very inefficient to go through let's say you had thousands of reviews or tens of thousands of review sentences and you wanted to run them through a model like this to try and figure out what aspects were good positive what aspects were negative it's obviously inefficient to do them one sentence at a time like this so that's where instruct abser comes in that's where now we're going to hop over to the code into the Jupiter notebook we'll take a look at it see how we can get it up and running and use it to perform the analysis for our business all right so here we are on the instruct Absa GitHub repo page just wanted to briefly take a look at this go over a few things just so everyone's on the same page so the main place we're going to be taking a look at in this video is this Joint Task training and inference notebook The Joint Task is the task where you give it a review or a review sentence and it will take a look at that sentence extract the aspects whether that's food whether that's the battery whether that's the service and then it assigns a sentiment to that aspect saying it's good or positive negative neutral based on the words around it that's the Joint Task there's also this at task which uh just extracts the aspect there's also an inference notebook this is where you have your model the default is just this instruct instruct Absa model not fine-tuned to your data and then you can speed it a sample sentence and it will spit out the results it's got a few different tasks here you can see uh going back a couple Pages we've got the instructions. piy which is a bunch of sets of instructions based on the given task that you're trying to do and it also has two sets for each task BOS instruct one and BOS instruct 2 BOS stands for beginning of sentence instruction that's what you feed to the model before you input your actual test that you want to translate basically giving it a prompt saying this is what I want you to do the reason there's two is because it was trained uh on both the laptop the laptop in the restaurant data sets there seems to be two standard data sets that they use for these types of tests the laptop reviews and then the restaurant reviews so there's different sets of instructions for each of those um here's the data sets folder this is where it's going to store the data sets for its tasks its test meaning instruct ABS as default tasks but when you clone this repo to your computer you can also store your own data sets in those folders just to make things a little easier so you don't have to modify too many file paths so you scroll down you can see uh just give some more information the big thing here is going to be this data set requirements it shows you how to how the format that you're supposed to have your data in so that the model can be trained effectively and there's a very specific format here as far as how you want it laid out a little bit later I'll actually show you a tool that I made to make this hopefully easier if you're going to be annotating your own data set sets uh just some more information here uh this instruct absit 2 for the Joint Task is somewhat relevant but I'll cover that when we go through the notebook and then the rest just more information if you want to run it from the CLI or something like that all right so here we are in The Joint Task H training and inference notebook that I referenced just a minute ago to get to this point you would clone the repo you would install the requirements.txt file and then you would launch up Jupiter notebook and get to this point that's assuming you want to run it on your local PC and not in collab which is also an option but I'll scroll down through this uh and just go over some of the things because there are going to be some problems if you try and run the cells in the notebook as is it's not completely updated so I wanted to show you real quick the changes you have to make to get it to work so just going to scroll down through this obviously you'll change your root path whatever you're working with I've changed mine uh then we'll go down to this training section you can change the experiment name to whatever you want and the model checkpoint you'll see I've updated to this Kevin scaria model that is on hugging face if you go back to the original notebook you'll see here that it's set as the Allen AI TK model that's the model that instruct abza was actually trained on but we want to fine-tune the instruct abza model does that make sense it was trained it was fine-tuned on Allen AI we want to fine-tune it so that's why we're updating the model checkpoint name and then the next cell these data sets the default is going to just be the laptop train and test you can update those to whatever you name your data sets probably best to just store them in the same folder so you don't have to change too much about the path and then when we try to run this cell as is let's say we update our data sets we have them to the past that we want and then we try to run this data set excuse me run this cell you'll see we get an error here it says the data set loader has no attribute create data in joint tesk format and this is where the notebook is a little bit at a date the default one you have to actually change this Joint Task in all its places you'll see that joint. joint you have to actually change that from joint or Joint Task to ASP so I'm going to do that real quick just to show you in real time how you do it instead of joint task you'll highlight it here and then it's going to be ASP that's assuming we're doing the still doing the Joint Task the aspect sentiment polarity and polarity extraction where we want both the aspect and the sentiment you'll change it in all the different spots here just like that now the other thing here you'll see in this comment it says at the beginning of the uh sentence instruction one for laptop and BOS instruct two for restaurant so I've already changed BOS to changed it to bos2 because my data set is a restaurant data set but you can change that to whatever is appropriate for you and also like it says you can modify the instructions. py file to include if you have a I don't know let's say you have a trucking business and you want to evaluate reviews for your trucking business you could set up some sample instructions there to get a little bit better accuracy so once we make those changes and then we go and run this set it runs fine and it'll move us to the next one uh this cell is all the training Arguments for the model when you go through your train hang on model checkpoint is not defined why are we getting that did we run this we did not run this that is why so now we're not getting an error but it's loading so we'll move on to this next one this is the actual train function and this is also where it's going to be a little bit out of date because I see I've already tried to run this cell and as it goes through the training process and you only have a train and a test set if you only have those two sets you'll actually get this error from the trainer function it's going to require an evaluation data set as you can see here and this is pretty frustrating because a lot of times you'll get decent ways into training which can take quite a long time I forget how long this took it took quite a while even though my sample sets are us really small in this case they're only like 20 samples long and still it took quite a while to get to this point because I'm running on a CPU only to get this error and tell me that I need the evaluation data set but anyway to avoid that error which we're going to do is split up your data set into not just a train and a test set but a train a validation and a test set which is pretty easy to do if you're comfortable with the train test split function but just for ease of everyone's use so you don't have to go and manually modify this what I actually did is I forked this repository and I made these changes in the notebook so if you want to do the Joint Task all you have to do is simply clone that repository and this notebook will be updated with all these changes automatically so you don't have to worry about getting everything perfectly right uh it has a section for splitting your data into train validation and test and likewise down here for this inference section we run into some of the same problems you'll see it's still at joint test down here so if you wanted to actually you know evaluate your model see how it did on the train set test it against maybe the Baseline instruct abza you would have to modify these cells as well all that's been done so that all you need to do is make sure you have the right instructions file and then obviously customize it with your own data sets and your own experiment name and file path so I'm going to take a quick look at that we'll switch right over I'll show you that real quick and then we'll look at that data annotation tool and wrap up all right so here we are in the updated notebook in in the new repository and I'll leave a link to this repository in the video description this is the fork repository that I made so I can make some changes to the notebook make it a little bit easier so everyone doesn't have to change everything manually if you scroll down you can see I've added some comments here to where you can enter your own details there's the file path your experiment name you can see the model checkpoint has already been updated so you don't have to change that can change your uh data set path and then the Joint Task has all been changed to ASP you'll still need to update the beginning of sentence instruction depending on what you need to do but that's just automatically set at two for restaurant we've got training arguments and then here's the big thing it's creating this validation set obviously it lets you know it's going to get an error if you don't create one and then it's got the code to actually create one so we'll use the train test split function to split the tokenized data set uh the test set into two and you can do whatever size you want we're just splitting it evenly into two half and half as you can see there and then in the next part because it's split now that this ID tokenized data set was split into two a train and test set we're just creating a test set with one half and a validation set set with the other half and when you print this out I haven't run this cell or anything but when you print this out you'll actually see how it's now divided into three separate parts you got the train you got the validation and you got the test and then I have tested this when you run the code you will no longer encount an error when you run this train function so that'll solve that problem it still will take a while probably depending on what you're running it on but you will no longer get the error and you'll be able to fine-tune your model and then going down below the inference has all been updated as well so all you need to do is update your data set as above change the instructions if you need to and run it and you'll be able to get the accurate output and compare your model versus a baseline compare different versions of your model and so on okay so the last thing I wanted to do was show you the data annotation tool this is a tool that you can use to annotate your reviews in the format that instruct abs and needs to perform the fine tuning on on them obviously to do that by hand for potentially hundreds of thousands of reviews would be extremely timec consuming so be nice to have a tool to make it a little bit quicker even though there's still not a great way to do it super quickly so it's just a little bit of manual labor but a tool like this definitely speeds it up so I'll show you the tool here this is just the code and Pie charm I will up load this to the GitHub repost so you have access to it but I wanted to quickly go over what's going on here so this first part here this is essentially taking your CSV file where you have all of your reviews just paste it into a column I'll show you here we go all these reviews each one is just in the a column its own separate row is its own review this is its review there's a duplicate that's what it looks like this is your data frame not your data frame this is your CSV file right here obviously mine's on my desktop you can have yours wherever this is going to point to just your CSV file with your reviews and what you do by running this block of code is it's going to create a new data frame and a new CSV file breaking each of those reviews into individual sentences using these four Loops it'll take each review so it'll take this review for instance which has four sentences and it will break up each sentence so that instead there's four separate rows each with one sentence a piece that's what this block of code does and you can see I've commented it here you only need to in you only need to do this one time and then you can comment this block of code out you won't need to run it again unless you're doing it with a new set of reviews but that's what this first section does and then when you actually run the code here's what the app looks like so I've got my tool here you can see this sentence here I loved the food so much corresponds with the very first sentence of the very first review that we're at the very top of the CSV file I love the food here so much but I have to say the service was lacking blah blah blah so it basically just breaks it all down into sentences and then what you can do from here is for each sentence you highlight any aspects that are in the sentence in this case food is an aspect and then you assign the sentiment to it so you highlight it with your cursor and then you click positive and you'll see we get the uh dictionary format down here with term polarity as the keys and then the specific aspect and the sentiment as the values and once you have that value loaded in there you'll hit next and it's going to take you to the next sentence you can see but I have to say the service was lacking and the food order process wasn't my favorite you can see that sentence now is loaded up in our annotation tool and you just do it again we've got an aspect service with negative sentiment food ordering process probably more accurate we'll say ordering process is an aspect they didn't like that was negative as well we'll hit next takes you to the next sentence and you just keep doing this for every sentence of every review so like I said it's not going to be blazing fast it's still a little bit of a manual process but it's a lot faster than literally typing that every single time uh it'll save you a ton of time on that front if there's no aspects in a particular sentiment you can just hit next and it'll basically just leave that row blank and that's fine too um but yeah you just keep doing this we can say Wings they're just okay so you would hit negative hit next and then here's a cool feature of this app let's say you know we got a pretty long CSV file with a lot of reviews let's say we've done it for a little wow we want to take a break what you can do if you just X Out of the app it will actually save your progress in whatever CSV file you have so if we go down to the save function we saved it to annotated sentences. CSV and we have that loaded up over here and we can see that the last sentence that we did which was this garlic parm wings that that's the last one that has any aspect terms loaded after it the rest are all just blank because we didn't reach those yet and so what you'll want to do to start back up since we've already done this step and converted our CSV file to this new data frame or CSV file of just sentences we don't have to do that again we can comment out this code and down here when it's asking us what's the CSV file we want to use to load up we'll actually use the one we just created in our case it's annotated sentences. CSV so we'll have to change that as well there's probably an easier way to do this but I just wrote this for myself and know I'm sharing it so if you want to modify the code to make it a little bit more uh intuitive for yourself feel free but now when we start it back up we're going to start where we were before so if we go back to annotated sentences after this bar garlic parm Wings sentence where we assign the sentiment the next was the wings were just okay that's where we start the wings were just okay neutral just okay blah blah we keep going we do this we can save it again it'll save our progress if we come back here and run it start starts back up where we left off so that's how you can more quickly go through and annotate the data for your instruct amum model and the last thing I wanted to go over was in addition to The annotation tool I also wrote up a couple of helper functions to clean up the annotated data set once you're all done with it as well as split it up into training test sets if you'd like to do that as well so once you've done gone through and annotated your entire data set you're going to have a bunch of terms like this one where it's just a blank with no aspect taken out of it so there's not there's basically no data from it this first function here the remove blank terms that's going to eliminate all of those rows and then save it into a new CSV file just to clean up the data a little bit so it's easier when you go in and make it into a data frame second one pretty self-explanatory it's just going to split the data into a train and test split you can adjust these however you want to it's 7030 by default and obviously you can change where you save the file so I'll go ahead and upload all these files that we've discussed on the GitHub that I'll link in the description below but this is basically the end of the quick tutorial of how to get instruct Absa up and running at least for the joint test for the most part even if you're trying to do some of the other tests TS this will probably be helpful I would think troubleshoot some of the stuff if you encounter any errors these were the problems that I encountered when trying to set up instruct abza for the first time because there's not a ton of documentation on it things get out of date and I just wanted to help out anyone else who might be trying to use this repo because it is a very very useful function I think and it can be used for a lot of good things uh create some really good business insights if use it appropriately so just wanted to help out anybody who was running into the same struggles that I was by all means if you have any questions please leave them in the comments below one thing that I didn't cover in this video that I might cover in a future video is how to actually scrape reviews off of Yelp and Google and that sort of thing to get data for your data set uh this sort all this tutorial basically assumes you already have that data but that can be a challenge as well to getting that so perhaps in the future I'll create a tutorial on how to do that but this is pretty much it for instruct Absa if I have any follow-up things that come up I'll post another video like I said if you have any questions leave them below I'll try to answer but thanks for watching you have a great rest of your day

what's going on everybody just a real quick hitter today wanted to quickly go over intense scoping in voice flow because I was just working on a project and I came across an issue that's not super obvious when you're first learning a voice flow and when you're going through a lot of the tutorials so I'll just show you what I mean real quick we'll start this flow from here uh we're not going to worry too much about what's actually going on it's mostly just intense scoping and how the conversation can sometimes route ways you don't want so it's asking for an email address in this case to check the status of an order I'm going to put in this particular email address which is triggering the intent so basically what happens here is that we're checking the St the status of an order and it asks for an email I put in my email address and then for whatever reason this join Rewards program intent thinks that I want to join the rewards program and instead of checking my order status it jumps me completely out of that flow and starts me down this join Rewards program flow so obviously that would be a bad user experience if that actually happened to a customer so the way to fix this is to go back to the capture step where we were capturing the email you'll select it and we just want to capture the email we don't want to look anywhere else for any other intents we don't want to listen for any anything else going on we just want to capture the email so you'll click the step you'll click this little settings go to intense scoping and instead of listening for all intents you only want to listen for intents in this step which are actually there's no intents in this step listed we're just capturing the email and saving it to a variable that's all we're doing so we change that we'll run this again just to make sure it works good so we're getting the order information the order status to pull through now you can see it did still detect that intent uh I can troubleshoot that didn't figure out why it's picking up that intent from this email it doesn't make too much sense to me at first glance but even so even though it picked up the intent it didn't transfer me to a whole different part of the flow it just continued down this flow and retrieved the order information which is exactly what we want so that's it for this video just a real quick hitter on how you can fix this fairly common but frustrating issue if you haven't seen it before and know how to fix it so it's what I wanted to go over thank you for watching

hello hi my name is Natasha I'm calling from John Smith's office at Big Money advisers am I speaking with Rob win No actually that's my dad my name is Dave ah I see could I please speak to Rob win if he's unavailable I'll call back later I think he's around here somewhere give me just a minute sure take your time I'll wait hello this is Rob win hi Rob my name is Natasha and I'm calling from John Smith's office at Big Money advisers it's nearly time for your annual financial review and John would like to schedule a time with you what date and time works best for you oh yeah give me just a minute I need to check my calendar of course take your time all right what does he have on November 18th hold on a sec John is available on November 18th at 11: a.m. 12:00 p.m. or 1 p.m. which time works best for you is there any way he could do 9900 a.m. this will just take a sec unfortunately John is not available at 9:00 a.m. on November 18th how about 11: am. 12: p.m or 1 p.m instead let's go ahead and do the 11: a.m. one moment great your appointment is confirmed for November 18th at 11: a.m. thank you rob have a great day you too thanks you're welcome take care so that was an interaction with an AI appointment CER I've been working on for the past few days I've been having a lot of fun working with this here's what's going on behind the scenes we have our basic prompt here in vapy telling it what its role is how to go about doing its job the functions to call uh some sample things a customer might say and how it should respond and then over here in make when it calls the function basically what we have here is these open a modules that are determining what day the customer is actually talking about and assuming they don't say something very specific like no Monday November 18th 2024 because a lot of times we'll just say next week or next Wednesday or tomorrow things like that and then it'll return a list of available time slots and then depending on the function that's being called if it's if we're just checking the availability of a particular time uh we'll go down this route this is if there are no previously scheduled commitments that day then we can just say hey pick a time any time is good if there are then we're going to use another open AI model to actually return some available time slots given what's already scheduled in the day and then once the customer says yeah that sounds good this is how we actually book the appointment using a couple open AI modules to once again just double check that we're not booking something for a time that already been scheduled that's what these are doing just double-checking making sure there's no conflict if there is will say sorry there's actually a conflict at that particular time so really liking how this project is shaping up this is just a Bare Bones voice appointment C there's still a ton of functionality and customizability I would like to build out into this thing but it's got me excited because because having AI handle things like appointment setting and other mundane tasks like that would just free up so much time for actual humans to take care of the stuff that really matters and really moves the needle so that's what I've been working on lately just wanted to give a glimpse uh a little prototype and if you're interested in learning more feel free to reach out to me shoot me a DM I'd be happy to discuss it further and one last thing special shout out to Hinrich over at lunaris AI he has a ton of great tutorials on voice agents so if you're interested in this kind of thing be sure and check out his YouTube channel it was a great help to me in building this one

